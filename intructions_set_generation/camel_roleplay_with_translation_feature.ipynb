{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1x1N-vi5nol"
      },
      "source": [
        "# Setting up the BharatAI translation-application for English->Indic translation (Optional). Estimated time taken - 10-20 minutes\n",
        "\n",
        "# If choosing not to set up the translation app, it's better to choose a CPU runtime to avoid warnings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcf3YRS24GEL",
        "outputId": "f364ba2c-d972-4859-a78c-083e9e840dc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'indicTrans'...\n",
            "remote: Enumerating objects: 697, done.\u001b[K\n",
            "remote: Counting objects: 100% (400/400), done.\u001b[K\n",
            "remote: Compressing objects: 100% (160/160), done.\u001b[K\n",
            "remote: Total 697 (delta 278), reused 342 (delta 238), pack-reused 297\u001b[K\n",
            "Receiving objects: 100% (697/697), 2.64 MiB | 22.51 MiB/s, done.\n",
            "Resolving deltas: 100% (405/405), done.\n",
            "/content/indicTrans\n",
            "Cloning into 'indic_nlp_library'...\n",
            "remote: Enumerating objects: 1399, done.\u001b[K\n",
            "remote: Counting objects: 100% (180/180), done.\u001b[K\n",
            "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
            "remote: Total 1399 (delta 135), reused 147 (delta 120), pack-reused 1219\u001b[K\n",
            "Receiving objects: 100% (1399/1399), 9.57 MiB | 12.91 MiB/s, done.\n",
            "Resolving deltas: 100% (745/745), done.\n",
            "Cloning into 'indic_nlp_resources'...\n",
            "remote: Enumerating objects: 139, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 139 (delta 2), reused 2 (delta 0), pack-reused 126\u001b[K\n",
            "Receiving objects: 100% (139/139), 149.77 MiB | 13.72 MiB/s, done.\n",
            "Resolving deltas: 100% (53/53), done.\n",
            "Cloning into 'subword-nmt'...\n",
            "remote: Enumerating objects: 597, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 597 (delta 8), reused 12 (delta 4), pack-reused 576\u001b[K\n",
            "Receiving objects: 100% (597/597), 252.23 KiB | 18.02 MiB/s, done.\n",
            "Resolving deltas: 100% (357/357), done.\n",
            "/content\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Collecting mock\n",
            "  Downloading mock-5.1.0-py3-none-any.whl (30 kB)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.3.2-py3-none-any.whl (119 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.7/119.7 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboardX\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (9.0.0)\n",
            "Collecting indic-nlp-library\n",
            "  Downloading indic_nlp_library-0.92-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacremoses) (2023.6.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.3.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sacremoses) (4.66.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Collecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (23.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n",
            "Collecting sphinx-argparse (from indic-nlp-library)\n",
            "  Downloading sphinx_argparse-0.4.0-py3-none-any.whl (12 kB)\n",
            "Collecting sphinx-rtd-theme (from indic-nlp-library)\n",
            "  Downloading sphinx_rtd_theme-1.3.0-py2.py3-none-any.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting morfessor (from indic-nlp-library)\n",
            "  Downloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: sphinx>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from sphinx-argparse->indic-nlp-library) (5.0.2)\n",
            "Requirement already satisfied: docutils<0.19 in /usr/local/lib/python3.10/dist-packages (from sphinx-rtd-theme->indic-nlp-library) (0.18.1)\n",
            "Collecting sphinxcontrib-jquery<5,>=4 (from sphinx-rtd-theme->indic-nlp-library)\n",
            "  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.7)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.5)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.0.4)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.1.9)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.6)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.1.2)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.16.1)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.2.0)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.13.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (0.7.13)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.4.1)\n",
            "Requirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.3->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2023.7.22)\n",
            "Installing collected packages: morfessor, tensorboardX, sacremoses, portalocker, mock, colorama, sacrebleu, sphinxcontrib-jquery, sphinx-rtd-theme, sphinx-argparse, indic-nlp-library\n",
            "Successfully installed colorama-0.4.6 indic-nlp-library-0.92 mock-5.1.0 morfessor-2.0.6 portalocker-2.8.2 sacrebleu-2.3.2 sacremoses-0.1.1 sphinx-argparse-0.4.0 sphinx-rtd-theme-1.3.0 sphinxcontrib-jquery-4.1 tensorboardX-2.6.2.2\n",
            "Collecting mosestokenizer\n",
            "  Downloading mosestokenizer-1.2.1.tar.gz (37 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting subword-nmt\n",
            "  Downloading subword_nmt-0.3.8-py3-none-any.whl (27 kB)\n",
            "Collecting docopt (from mosestokenizer)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting openfile (from mosestokenizer)\n",
            "  Downloading openfile-0.0.7-py3-none-any.whl (2.4 kB)\n",
            "Collecting uctools (from mosestokenizer)\n",
            "  Downloading uctools-1.3.0.tar.gz (4.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting toolwrapper (from mosestokenizer)\n",
            "  Downloading toolwrapper-2.1.0.tar.gz (3.2 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: mock in /usr/local/lib/python3.10/dist-packages (from subword-nmt) (5.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from subword-nmt) (4.66.1)\n",
            "Building wheels for collected packages: mosestokenizer, docopt, toolwrapper, uctools\n",
            "  Building wheel for mosestokenizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mosestokenizer: filename=mosestokenizer-1.2.1-py3-none-any.whl size=49171 sha256=605815a39fad4f0683fc1181a64c8bde847f161811c72224dbe3eac8214dbe75\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/d8/15/4c5ebbe883513f003cb055a0369c77c9df857023a706f39e70\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=2136d283c12fe9b957a021e40c1b2ded054f01fd91c8bc2d99d85bad89f1522d\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "  Building wheel for toolwrapper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for toolwrapper: filename=toolwrapper-2.1.0-py3-none-any.whl size=3337 sha256=6bc0e37d82739ccb04881ed5f55e8c573f646f0728c39445c475314b2f6dace4\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/af/b1/99b57a06dda78fdcee86d2e22c64743f3b8df8f31cfc04baf7\n",
            "  Building wheel for uctools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for uctools: filename=uctools-1.3.0-py3-none-any.whl size=6147 sha256=3e613b43b5f8eb38906c035d0400a0ff22926291e6ea5303a46ce1e5b8e0a8f0\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/ee/10/33257b0801ac6a912c841939032c16da1eb3db377afe1443e5\n",
            "Successfully built mosestokenizer docopt toolwrapper uctools\n",
            "Installing collected packages: toolwrapper, openfile, docopt, uctools, subword-nmt, mosestokenizer\n",
            "Successfully installed docopt-0.6.2 mosestokenizer-1.2.1 openfile-0.0.7 subword-nmt-0.3.8 toolwrapper-2.1.0 uctools-1.3.0\n",
            "Cloning into 'fairseq'...\n",
            "remote: Enumerating objects: 34933, done.\u001b[K\n",
            "remote: Counting objects: 100% (83/83), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 34933 (delta 56), reused 53 (delta 36), pack-reused 34850\u001b[K\n",
            "Receiving objects: 100% (34933/34933), 25.10 MiB | 16.15 MiB/s, done.\n",
            "Resolving deltas: 100% (25363/25363), done.\n",
            "/content/fairseq\n",
            "Processing /content/fairseq\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (1.16.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (3.0.5)\n",
            "Collecting hydra-core<1.1,>=1.0.7 (from fairseq==0.12.2)\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<2.1 (from fairseq==0.12.2)\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: numpy>=1.21.3 in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (1.23.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (2023.6.3)\n",
            "Requirement already satisfied: sacrebleu>=1.4.12 in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (2.3.2)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (4.66.1)\n",
            "Collecting bitarray (from fairseq==0.12.2)\n",
            "  Downloading bitarray-2.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.4/287.4 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (2.1.0+cu118)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (1.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (23.2)\n",
            "Collecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq==0.12.2)\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq==0.12.2) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq==0.12.2) (4.5.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq==0.12.2) (2.8.2)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq==0.12.2) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq==0.12.2) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq==0.12.2) (4.9.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (2.1.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->fairseq==0.12.2) (2.21)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fairseq==0.12.2) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fairseq==0.12.2) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fairseq==0.12.2) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->fairseq==0.12.2) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->fairseq==0.12.2) (1.3.0)\n",
            "Building wheels for collected packages: fairseq, antlr4-python3-runtime\n",
            "  Building wheel for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-0.12.2-cp310-cp310-linux_x86_64.whl size=19952900 sha256=e51b8b5ada3fd3c3ea2ad5bf90b51fb9056822e5fd1f9359c78953d1425525e5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-w80gjyy3/wheels/c6/d7/db/bc419b1daa8266aa8de2a7c4d29f62dbfa814e8701fe4695a2\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141210 sha256=1953f1471baf963da1d3138f25c0c2499bf7d1bea917d17793c236c5b3717b73\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n",
            "Successfully built fairseq antlr4-python3-runtime\n",
            "Installing collected packages: bitarray, antlr4-python3-runtime, omegaconf, hydra-core, fairseq\n",
            "Successfully installed antlr4-python3-runtime-4.8 bitarray-2.8.3 fairseq-0.12.2 hydra-core-1.0.7 omegaconf-2.0.6\n",
            "Collecting xformers\n",
            "  Downloading xformers-0.0.22.post7-cp310-cp310-manylinux2014_x86_64.whl (211.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.8/211.8 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers) (1.23.5)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from xformers) (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->xformers) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->xformers) (1.3.0)\n",
            "Installing collected packages: xformers\n",
            "Successfully installed xformers-0.0.22.post7\n",
            "/content\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:xformers:WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
            "    PyTorch 2.1.0+cu121 with CUDA 1201 (you have 2.1.0+cu118)\n",
            "    Python  3.10.13 (you have 3.10.12)\n",
            "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
            "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
            "  Set XFORMERS_MORE_DETAILS=1 for more details\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-24 06:15:42--  https://ai4b-public-nlu-nlg.objectstore.e2enetworks.net/en2indic.zip\n",
            "Resolving ai4b-public-nlu-nlg.objectstore.e2enetworks.net (ai4b-public-nlu-nlg.objectstore.e2enetworks.net)... 164.52.206.155, 101.53.136.18, 164.52.210.58, ...\n",
            "Connecting to ai4b-public-nlu-nlg.objectstore.e2enetworks.net (ai4b-public-nlu-nlg.objectstore.e2enetworks.net)|164.52.206.155|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4811880516 (4.5G) [application/zip]\n",
            "Saving to: ‘en2indic.zip’\n",
            "\n",
            "en2indic.zip        100%[===================>]   4.48G  53.6MB/s    in 92s     \n",
            "\n",
            "2023-11-24 06:17:15 (49.9 MB/s) - ‘en2indic.zip’ saved [4811880516/4811880516]\n",
            "\n",
            "Archive:  en2indic.zip\n",
            "   creating: en-indic/\n",
            "   creating: en-indic/vocab/\n",
            "  inflating: en-indic/vocab/bpe_codes.32k.SRC  \n",
            "  inflating: en-indic/vocab/vocab.SRC  \n",
            "  inflating: en-indic/vocab/vocab.TGT  \n",
            "  inflating: en-indic/vocab/bpe_codes.32k.TGT  \n",
            "   creating: en-indic/final_bin/\n",
            "  inflating: en-indic/final_bin/preprocess.log  \n",
            "  inflating: en-indic/final_bin/dict.TGT.txt  \n",
            "  inflating: en-indic/final_bin/test.SRC-TGT.SRC.idx  \n",
            "  inflating: en-indic/final_bin/test.SRC-TGT.TGT.idx  \n",
            "  inflating: en-indic/final_bin/train.SRC-TGT.SRC.idx  \n",
            "  inflating: en-indic/final_bin/dict.SRC.txt  \n",
            "  inflating: en-indic/final_bin/valid.SRC-TGT.TGT.idx  \n",
            "  inflating: en-indic/final_bin/test.SRC-TGT.TGT.bin  \n",
            "  inflating: en-indic/final_bin/valid.SRC-TGT.TGT.bin  \n",
            "  inflating: en-indic/final_bin/train.SRC-TGT.TGT.idx  \n",
            "  inflating: en-indic/final_bin/train.SRC-TGT.TGT.bin  \n",
            "  inflating: en-indic/final_bin/valid.SRC-TGT.SRC.idx  \n",
            "  inflating: en-indic/final_bin/train.SRC-TGT.SRC.bin  \n",
            "  inflating: en-indic/final_bin/valid.SRC-TGT.SRC.bin  \n",
            "  inflating: en-indic/final_bin/test.SRC-TGT.SRC.bin  \n",
            "   creating: en-indic/model/\n",
            "  inflating: en-indic/model/checkpoint_best.pt  \n",
            "/content/indicTrans\n",
            "Initializing vocab and bpe\n",
            "Initializing model for translation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 117.71it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ଜନ୍ମଦିନର ଶୁଭେଚ୍ଛା! ଏହି ବିଶେଷ ଦିନ ଆପଣମାନଙ୍କ ପାଇଁ ଆନନ୍ଦ, ହସ ଏବଂ ସମସ୍ତ ଆଶୀର୍ବାଦ ଆଣିଦେଉ।',\n",
              " 'ଗତ ସଦସ୍ୟ ବୈଠକରେ କ୍ଲବକୁ ଉନ୍ନତ କରିବା ପାଇଁ 5ଟି ବିଚାର ତାଲିକା ପ୍ରସ୍ତୁତ କରାଯାଉ।',\n",
              " 'ଏକ ଷ୍ଟକର କ୍ରୟ ଏବଂ ବିକ୍ରୟର ସର୍ବାଧିକ ଲାଭ ଖୋଜିବା ପାଇଁ ଏକ ଆଲଗୋରିଦମ ପ୍ରସ୍ତୁତ କରିବେ କି?']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!git clone https://github.com/AI4Bharat/indicTrans.git\n",
        "%cd indicTrans\n",
        "# clone requirements repositories\n",
        "!git clone https://github.com/anoopkunchukuttan/indic_nlp_library.git\n",
        "!git clone https://github.com/anoopkunchukuttan/indic_nlp_resources.git\n",
        "!git clone https://github.com/rsennrich/subword-nmt.git\n",
        "%cd ..\n",
        "!pip install sacremoses pandas mock sacrebleu tensorboardX pyarrow indic-nlp-library\n",
        "! pip install mosestokenizer subword-nmt\n",
        "# Install fairseq from source\n",
        "!git clone https://github.com/pytorch/fairseq.git\n",
        "%cd fairseq\n",
        "# !git checkout da9eaba12d82b9bfc1442f0e2c6fc1b895f4d35d\n",
        "!pip install ./\n",
        "! pip install xformers\n",
        "%cd ..\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += \":/content/fairseq/\"\n",
        "# sanity check to see if fairseq is installed\n",
        "from fairseq import checkpoint_utils, distributed_utils, options, tasks, utils\n",
        "!wget https://ai4b-public-nlu-nlg.objectstore.e2enetworks.net/en2indic.zip\n",
        "!unzip en2indic.zip\n",
        "\n",
        "# # downloading the indic-indic model\n",
        "# !wget https://ai4b-public-nlu-nlg.objectstore.e2enetworks.net/m2m.zip\n",
        "# !unzip m2m.zip\n",
        "\n",
        "%cd indicTrans\n",
        "from indicTrans.inference.engine import Model\n",
        "\n",
        "indic2en_model = Model(expdir='../en-indic')\n",
        "ta_sents = ['Happy birthday! May this special day bring you joy, laughter, and all the blessings you deserve. Have a wonderful year ahead!',\n",
        "            'During the last member meeting, create a list of 5 ideas to improve the club.',\n",
        "            'Design an algorithm to find the maximum profit of a stock buy and sell?']\n",
        "\n",
        "\n",
        "indic2en_model.batch_translate(ta_sents, 'en', 'or')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMBAzy7T6KdF"
      },
      "source": [
        "#Setting up the camel-ai for conversation generation (Required)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QF4jQhwR4Ppn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c7a4d47-9daf-47fd-b9f9-14fdefec16ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/camel-ai/camel.git@v0.1.0\n",
            "  Cloning https://github.com/camel-ai/camel.git (to revision v0.1.0) to /tmp/pip-req-build-67b7jvok\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/camel-ai/camel.git /tmp/pip-req-build-67b7jvok\n",
            "  Running command git checkout -q bda4bf43bb03092936c2c0316aee9ff96aa551bf\n",
            "  Resolved https://github.com/camel-ai/camel.git to commit bda4bf43bb03092936c2c0316aee9ff96aa551bf\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from camel==0.1.0) (1.23.5)\n",
            "Collecting openai (from camel==0.1.0)\n",
            "  Downloading openai-1.3.5-py3-none-any.whl (220 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.8/220.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (from camel==0.1.0) (8.2.3)\n",
            "Collecting tiktoken (from camel==0.1.0)\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from camel==0.1.0) (0.4.6)\n",
            "Requirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai->camel==0.1.0) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai->camel==0.1.0) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai->camel==0.1.0)\n",
            "  Downloading httpx-0.25.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai->camel==0.1.0) (1.10.13)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai->camel==0.1.0) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai->camel==0.1.0) (4.5.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->camel==0.1.0) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->camel==0.1.0) (2.31.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai->camel==0.1.0) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai->camel==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai->camel==0.1.0) (1.1.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai->camel==0.1.0) (2023.7.22)\n",
            "Collecting httpcore (from httpx<1,>=0.23.0->openai->camel==0.1.0)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->camel==0.1.0) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->camel==0.1.0) (2.0.7)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore->httpx<1,>=0.23.0->openai->camel==0.1.0)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: camel\n",
            "  Building wheel for camel (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for camel: filename=camel-0.1.0-py3-none-any.whl size=35373 sha256=f81554979c83bf794599d4d9fccedaadb553c1ebbcd2c2a4889f5ab4886fca21\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zcj4b700/wheels/da/d0/fa/fc43c5ffd9b048aaf00cbce096486d30e3f4f3ddeb9ac126b0\n",
            "Successfully built camel\n",
            "Installing collected packages: h11, tiktoken, httpcore, httpx, openai, camel\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed camel-0.1.0 h11-0.14.0 httpcore-1.0.2 httpx-0.25.1 openai-1.3.5 tiktoken-0.5.1\n",
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.3.5\n",
            "    Uninstalling openai-1.3.5:\n",
            "      Successfully uninstalled openai-1.3.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.0\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/camel-ai/camel.git@v0.1.0 #Installing the camel-ai library for conversation generation\n",
        "!pip install openai==0.28\n",
        "\n",
        "import openai\n",
        "from colorama import Fore\n",
        "from camel.agents import RolePlaying\n",
        "from camel.utils import print_text_animated\n",
        "import pprint\n",
        "import random\n",
        "\n",
        "openai.api_key = '' #Enter your openai api-key here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9qQ41H-O5u3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conversation generator function below takes a user and an assistant. Providing a task is optional.\n",
        "\n",
        "#For lang = 'en' (English), you do not need  to setup the BharatAI-translation app.\n",
        "\n",
        "#If you want the conversation to be in an Indic language, the translation-app needs to be set up, which takes 10-20 minutes.\n"
      ],
      "metadata": {
        "id": "uulOvZ1D9MO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conversation_generator(user,assistant,chat_limit=2, task = None, lang = 'en'):\n",
        "\n",
        "  if task is None: #Using few shot inference to generate a conversation topic if not specified by the user. The camel library will take care of the specific task once a topic has been assigned.\n",
        "    user, assistant = user , assistant\n",
        "\n",
        "    prompt_random = f'''User: Actor, Assistant: Business analyst\n",
        "    Generate a conversation topic: Help an actor to decide which genre of movie to choose based on recent trends\\n\n",
        "    User: Accountant, Assistant: Student\n",
        "    Generate a conversation topic: Developing a custom accounting software to automate financial processes and reduce errors in account-keeping.\\n\n",
        "    User: Athlete, Assistant: Doctor\n",
        "    Generate a conversation topic: Developing a personalized nutrition plan for a Jewish athlete, to optimize athletic performance and recovery\\n\n",
        "    User: Industrialist, Assistant: Social Media Manager\\n\n",
        "    Generate a conversation topic: Develop a social media strategy to improve the impression of the industrialist through philanthropical activites\\n\n",
        "    User: Tourist, Assistant: Guide\n",
        "    Generate a conversation topic: Discuss why and how the Colosseum was built\n",
        "    User: Student, Assistant: Consultant\n",
        "    Generate a conversation topic: Help a student to choose which stream to choose\n",
        "    User: {user}, Assistant: {assistant}\n",
        "    Generate a conversation topic:'''\n",
        "\n",
        "    prompt_india = f'''User: Farmer, Assistant: Business analyst\n",
        "    Generate a conversation topic related to India: Help a farmer from dry areas of Rajasthan in deciding the optimal choice for crops this year\\n\n",
        "    User: Accountant, Assistant: Developer\n",
        "    Generate a conversation topic related to India: Developing a custom accounting software to automate financial processes and reduce errors in Bombay Stock Exchange.\\n\n",
        "    User: Athlete, Assistant: Doctor\n",
        "    Generate a conversation topic related to India: Developing a personalized nutrition plan for a North Indian Jain athlete, to optimize athletic performance and recovery.\\n\n",
        "    User: Politician, Assistant: Social Media Manager\\n\n",
        "    Generate a conversation topic related to India: Develop a social media strategy to increase the politician's online presence and engagement with constituents to help him win Madhya Pradesh elections.\\n\n",
        "    User: Tourist, Assistant: Guide\n",
        "    Generate a conversation topic related to India: Discuss why and how Hoysala temple was built in Karnataka\n",
        "    User: Student, Assistant: Consultant\n",
        "    Generate a conversation topic related to India: Help a CBSE student to opt for either JEE or NEET entrance exam\n",
        "    User: {user}, Assistant: {assistant}\n",
        "    Generate a conversation topic related to India:'''\n",
        "\n",
        "    choice = random.choice(['global','india'])\n",
        "\n",
        "    if choice == 'global':\n",
        "      prompt = prompt_random\n",
        "      content = \"You are a helpful assistant that provides information.\"\n",
        "    else:\n",
        "      prompt = prompt_india\n",
        "      content = \"You are a helpful assistant that provides information about India.\"\n",
        "\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": content},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    task = response.choices[0].message[\"content\"].strip()\n",
        "\n",
        "\n",
        "  task_prompt = task\n",
        "  print(f\"Original task prompt:\\n{task_prompt}\\n\")\n",
        "\n",
        "  assistant = assistant\n",
        "  user = user\n",
        "\n",
        "  role_play_session = RolePlaying(assistant, user, task_prompt)\n",
        "  print(f\"Specified task prompt:\\n{role_play_session.task_prompt}\\n\")\n",
        "\n",
        "  chat_turn_limit, n = chat_limit, 0\n",
        "  assistant_msg, _ = role_play_session.init_chat()\n",
        "\n",
        "  user_chat = []\n",
        "  assistant_chat = []\n",
        "\n",
        "  while n < chat_turn_limit:\n",
        "    n += 1\n",
        "    try:\n",
        "      (assistant_msg, _, _), (user_msg, _, _) = role_play_session.step(assistant_msg)\n",
        "      # print(n)\n",
        "      assert user_msg.content is not None\n",
        "      assert assistant_msg.content is not None\n",
        "    except:\n",
        "      break\n",
        "\n",
        "    user_chat.append(user_msg.content)\n",
        "    if \"Next request.\" not in assistant_msg.content:\n",
        "      break\n",
        "\n",
        "    assistant_chat.append(assistant_msg.content)\n",
        "    if \"<CAMEL_TASK_DONE>\" in user_msg.content:\n",
        "        break\n",
        "\n",
        "  #Processing the generated conversation\n",
        "\n",
        "  final_user_convo = []\n",
        "  final_assistant_convo = []\n",
        "\n",
        "  if len(assistant_chat)==0 or len(user_chat)==0:\n",
        "    return \"Empty list\"\n",
        "\n",
        "\n",
        "  for i in range(len(user_chat)):\n",
        "\n",
        "    if (\"Next request\" in assistant_chat[i]) and (\"Instruction:\" in user_chat[i]) and (\"Input:\" in user_chat[i]):\n",
        "      final_instruction = \"\"\n",
        "      try:\n",
        "        instruction = user_chat[i].split(\"Instruction:\")[1].split(\"Input:\")[0]\n",
        "        input = user_chat[i].split(\"Input:\")[1].strip()\n",
        "      except:\n",
        "        continue\n",
        "\n",
        "      if input.strip() == 'None':\n",
        "        final_instruction = final_instruction+instruction.replace(\"\\n\",\" \")\n",
        "        final_instruction = final_instruction.strip()\n",
        "      else:\n",
        "        final_instruction = instruction.replace(\"\\n\",\" \")+\"\\ninput:\"+input #If an input is there, then add a newline after instruction, input: and then the input.\n",
        "        final_instruction = final_instruction.strip()\n",
        "\n",
        "      final_user_convo.append(final_instruction)\n",
        "      final_assistant_convo.append(assistant_chat[i].replace(\"Solution:\",\"\").replace(\"Next request.\",\"\").strip())\n",
        "\n",
        "    else:\n",
        "      break #Sometimes faulty chat gets generated. A proper convo has Next request at the end\n",
        "\n",
        "  assert (len(final_user_convo)-len(assistant_chat)) <= 1\n",
        "  # print('\\n\\n'+'End of the conversation\\n\\n')\n",
        "  print(\"*\"*150, end='\\n')\n",
        "  final_convo_list = []\n",
        "\n",
        "  for i in range(len(final_user_convo)):\n",
        "    user_convo = {\"from\":\"user\",\"value\":final_user_convo[i]}\n",
        "    assistant_convo = {\"from\":\"assistant\",\"value\":final_assistant_convo[i]}\n",
        "    final_convo_list.append(user_convo)\n",
        "    final_convo_list.append(assistant_convo)\n",
        "\n",
        "  length = len(final_convo_list)\n",
        "  print(\"Number of conversations = \", length)\n",
        "  final_json_entry = {'user':user,'assistant':assistant,'task':task_prompt,'conversations':final_convo_list, 'specified_task':role_play_session.task_prompt, 'length':length}\n",
        "  # pprint.pprint(final_json_entry)\n",
        "\n",
        "  if lang == 'en':\n",
        "    return final_json_entry\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #Translating a conversation from English to Hindi or any Indic language\n",
        "  def translate_json(single_json, dest= 'hi'):\n",
        "    max_words = 130\n",
        "\n",
        "    def split_text(text, max_words=max_words): # Split the text into sentences based on full stops\n",
        "      sentences = text.split('.')\n",
        "\n",
        "      chunks = []\n",
        "      current_chunk = \"\"\n",
        "      word_count = 0\n",
        "\n",
        "      for sentence in sentences:\n",
        "          sentence = sentence.strip() + '.'\n",
        "          sentence_word_count = len(sentence.split())\n",
        "\n",
        "          if word_count + sentence_word_count <= max_words:\n",
        "              current_chunk += sentence + \" \"\n",
        "              word_count += sentence_word_count\n",
        "          else:\n",
        "              chunks.append(current_chunk.strip())\n",
        "              current_chunk = sentence + \" \"\n",
        "              word_count = sentence_word_count\n",
        "\n",
        "      if current_chunk:\n",
        "          chunks.append(current_chunk.strip())\n",
        "\n",
        "      return chunks\n",
        "\n",
        "    conversations = single_json['conversations']\n",
        "    assert len(conversations) > 0, \"Conversation is empty\"\n",
        "\n",
        "    translated_json = single_json.copy()\n",
        "\n",
        "    translated_conversation = conversations.copy() #Conversation defined as collection of all the exchanges between any given pair of user and assistant\n",
        "\n",
        "    translated_json['task'] = indic2en_model.translate_paragraph(single_json['task'], 'en', dest)\n",
        "    translated_json['specified_task'] = indic2en_model.translate_paragraph(single_json['specified_task'], 'en', dest)\n",
        "\n",
        "    for i in range(len(conversations)):\n",
        "\n",
        "      text = conversations[i]['value']\n",
        "\n",
        "      if len(text.split(\" \")) > max_words:\n",
        "        text_chunks = split_text(text)\n",
        "      else:\n",
        "        text_chunks = [text]\n",
        "\n",
        "      # pprint.pprint(text_chunks)\n",
        "\n",
        "      translated_chat = ' '.join(indic2en_model.batch_translate(text_chunks, 'en', dest)) #Chat is defined as a single exchange between a user and assistant\n",
        "      translated_conversation[i]['value'] = translated_chat\n",
        "\n",
        "    translated_json['conversations'] = translated_conversation\n",
        "\n",
        "    return translated_json\n",
        "\n",
        "  print(\"Conversation generation done! Translation happening now!\")\n",
        "  if lang == 'hi' or lang == 'hindi':\n",
        "    return translate_json(final_json_entry, dest = 'hi')\n",
        "\n",
        "\n",
        "#You can provide any role for user, same goes for assistant and task as well. In camel-ai interface, you have a limited set of roles and task to choose from.\n",
        "\n",
        "sample = conversation_generator(user = 'Farmer',\n",
        "                                assistant = 'Scientist',\n",
        "                                # task = \"How to maximize the profit of a potato farmer\",\n",
        "                                lang = 'en'\n",
        "                                )\n",
        "\n",
        "pprint.pprint(sample)\n",
        "# pprint.pprint(sample['conversations'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLLDlWkb_Req",
        "outputId": "7e269046-b0be-4338-9f65-e59c1943fac8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original task prompt:\n",
            "Develop drought-resistant crop varieties suitable for the farmers in Maharashtra.\n",
            "\n",
            "Specified task prompt:\n",
            "Develop a specialized drone equipped with advanced sensors and machine learning capabilities to detect and monitor crop diseases in real-time. This will enable farmers to proactively identify and treat affected areas, increasing crop yield and minimizing the use of agrochemicals. The scientist will collaborate with the farmer to fine-tune the drone's algorithms and ensure its effective implementation in the field. \n",
            "\n",
            "******************************************************************************************************************************************************\n",
            "Number of conversations =  4\n",
            "{'assistant': 'Scientist',\n",
            " 'conversations': [{'from': 'user',\n",
            "                    'value': 'Design a drone prototype with a lightweight '\n",
            "                             'frame and high maneuverability.'},\n",
            "                   {'from': 'assistant',\n",
            "                    'value': 'To design a drone prototype with a lightweight '\n",
            "                             'frame and high maneuverability, we can consider '\n",
            "                             'the following steps:\\n'\n",
            "                             '\\n'\n",
            "                             '1. Frame Material Selection: Choose lightweight '\n",
            "                             'materials such as carbon fiber or aluminum for '\n",
            "                             \"the drone's frame. These materials offer a good \"\n",
            "                             'balance between strength and weight, allowing '\n",
            "                             'for increased maneuverability.\\n'\n",
            "                             '\\n'\n",
            "                             \"2. Aerodynamic Design: Optimize the drone's \"\n",
            "                             'shape and structure to reduce drag and improve '\n",
            "                             'maneuverability. This can be achieved by '\n",
            "                             'incorporating streamlined features, such as a '\n",
            "                             'sleek body and angled arms, to minimize air '\n",
            "                             'resistance.\\n'\n",
            "                             '\\n'\n",
            "                             '3. Motor and Propeller Selection: Select motors '\n",
            "                             'and propellers that are specifically designed '\n",
            "                             'for agility and responsiveness. Look for high '\n",
            "                             'RPM (rotations per minute) motors and propellers '\n",
            "                             'with a high pitch angle, as these will provide '\n",
            "                             'the necessary thrust and maneuverability.\\n'\n",
            "                             '\\n'\n",
            "                             '4. Flight Controller and Software: Choose a '\n",
            "                             'flight controller that supports advanced flight '\n",
            "                             'modes and stabilization algorithms. This will '\n",
            "                             'allow for precise control and maneuverability. '\n",
            "                             'Additionally, develop or utilize software that '\n",
            "                             'optimizes flight dynamics and responsiveness.\\n'\n",
            "                             '\\n'\n",
            "                             '5. Testing and Iteration: Build a prototype '\n",
            "                             'based on the design and conduct thorough testing '\n",
            "                             'to evaluate its maneuverability. Make necessary '\n",
            "                             'adjustments and iterations to improve '\n",
            "                             'performance and ensure the drone meets the '\n",
            "                             'desired specifications.\\n'\n",
            "                             '\\n'\n",
            "                             'Example: The drone prototype will have a frame '\n",
            "                             'made of lightweight carbon fiber, which offers '\n",
            "                             'excellent strength-to-weight ratio. The frame '\n",
            "                             'will be aerodynamically designed with a sleek '\n",
            "                             'body and angled arms to minimize drag. It will '\n",
            "                             'be equipped with high RPM motors and propellers '\n",
            "                             'with a high pitch angle to provide the necessary '\n",
            "                             'thrust and maneuverability. The flight '\n",
            "                             'controller will support advanced flight modes '\n",
            "                             'and stabilization algorithms, ensuring precise '\n",
            "                             'control. Through testing and iteration, we will '\n",
            "                             'fine-tune the design to achieve optimal '\n",
            "                             'maneuverability.'},\n",
            "                   {'from': 'user',\n",
            "                    'value': 'Select and integrate advanced sensors suitable '\n",
            "                             'for crop disease detection on the drone.'},\n",
            "                   {'from': 'assistant',\n",
            "                    'value': 'To select and integrate advanced sensors '\n",
            "                             'suitable for crop disease detection on the '\n",
            "                             'drone, we can consider the following steps:\\n'\n",
            "                             '\\n'\n",
            "                             '1. Research and Identify Suitable Sensors: '\n",
            "                             'Conduct research to identify sensors that are '\n",
            "                             'capable of detecting crop diseases effectively. '\n",
            "                             'Some commonly used sensors for this purpose '\n",
            "                             'include multispectral cameras, thermal cameras, '\n",
            "                             'and hyperspectral sensors. Each sensor has its '\n",
            "                             \"own advantages and limitations, so it's \"\n",
            "                             'important to choose the ones that best suit the '\n",
            "                             'specific requirements of crop disease '\n",
            "                             'detection.\\n'\n",
            "                             '\\n'\n",
            "                             '2. Evaluate Sensor Specifications: Once the '\n",
            "                             'sensors are identified, evaluate their '\n",
            "                             'specifications such as spectral range, '\n",
            "                             'resolution, sensitivity, and field of view. '\n",
            "                             \"These specifications will determine the sensor's \"\n",
            "                             'ability to detect and differentiate between '\n",
            "                             'healthy and diseased crops.\\n'\n",
            "                             '\\n'\n",
            "                             '3. Consider Integration Compatibility: Ensure '\n",
            "                             'that the selected sensors can be integrated with '\n",
            "                             \"the drone's existing hardware and software \"\n",
            "                             'systems. This may involve checking compatibility '\n",
            "                             \"with the drone's communication protocols, power \"\n",
            "                             'requirements, and data storage capabilities.\\n'\n",
            "                             '\\n'\n",
            "                             '4. Mounting and Positioning: Determine the '\n",
            "                             'optimal mounting and positioning of the sensors '\n",
            "                             'on the drone. This will depend on factors such '\n",
            "                             \"as the sensor's field of view, the desired \"\n",
            "                             \"coverage area, and the drone's stability during \"\n",
            "                             \"flight. It's important to position the sensors \"\n",
            "                             'in a way that maximizes their effectiveness in '\n",
            "                             'capturing accurate and reliable data.\\n'\n",
            "                             '\\n'\n",
            "                             '5. Data Processing and Analysis: Develop or '\n",
            "                             'utilize software algorithms to process and '\n",
            "                             'analyze the data collected by the sensors. This '\n",
            "                             'may involve using machine learning techniques to '\n",
            "                             'classify and identify crop diseases based on the '\n",
            "                             \"sensor data. Ensure that the drone's onboard \"\n",
            "                             'computing capabilities are sufficient to handle '\n",
            "                             'the processing requirements.\\n'\n",
            "                             '\\n'\n",
            "                             '6. Testing and Calibration: Conduct thorough '\n",
            "                             'testing and calibration of the integrated '\n",
            "                             'sensors to ensure their accuracy and reliability '\n",
            "                             'in detecting crop diseases. This may involve '\n",
            "                             'comparing the sensor data with ground truth data '\n",
            "                             'collected manually or through other means.\\n'\n",
            "                             '\\n'\n",
            "                             'Example: After researching and evaluating '\n",
            "                             'various sensors, we have selected a '\n",
            "                             'multispectral camera and a thermal camera for '\n",
            "                             'crop disease detection. The multispectral camera '\n",
            "                             'will capture images in different spectral bands, '\n",
            "                             'allowing us to analyze the reflectance '\n",
            "                             'properties of crops and identify any anomalies '\n",
            "                             'associated with diseases. The thermal camera, on '\n",
            "                             'the other hand, will detect temperature '\n",
            "                             'variations in the crops, which can indicate the '\n",
            "                             'presence of diseases. These sensors will be '\n",
            "                             \"integrated with the drone's existing hardware \"\n",
            "                             'and software systems, ensuring compatibility and '\n",
            "                             'seamless operation. The sensors will be mounted '\n",
            "                             'and positioned strategically on the drone to '\n",
            "                             'capture comprehensive data during flight. The '\n",
            "                             'collected data will be processed and analyzed '\n",
            "                             'using machine learning algorithms to classify '\n",
            "                             'and identify crop diseases. Thorough testing and '\n",
            "                             'calibration will be conducted to validate the '\n",
            "                             'accuracy and reliability of the integrated '\n",
            "                             'sensors.'}],\n",
            " 'length': 4,\n",
            " 'specified_task': 'Develop a specialized drone equipped with advanced sensors '\n",
            "                   'and machine learning capabilities to detect and monitor '\n",
            "                   'crop diseases in real-time. This will enable farmers to '\n",
            "                   'proactively identify and treat affected areas, increasing '\n",
            "                   'crop yield and minimizing the use of agrochemicals. The '\n",
            "                   'scientist will collaborate with the farmer to fine-tune '\n",
            "                   \"the drone's algorithms and ensure its effective \"\n",
            "                   'implementation in the field. ',\n",
            " 'task': 'Develop drought-resistant crop varieties suitable for the farmers in '\n",
            "         'Maharashtra.',\n",
            " 'user': 'Farmer'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conversation in Indic language below\n",
        "# The translation app needs GPU to be fast-enough"
      ],
      "metadata": {
        "id": "xH8z_FOqDMii"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubu9M6kkDitJ",
        "outputId": "3deef71f-14ca-4133-bb38-0ad06078ad16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original task prompt:\n",
            "Discuss sustainable farming practices and their benefits for the environment and crop yields.\n",
            "\n",
            "Specified task prompt:\n",
            "Develop a soil microbial technology that improves crop productivity and resilience in challenging environments.\n",
            "\n",
            "******************************************************************************************************************************************************\n",
            "Number of conversations =  4\n",
            "Conversation generation done! Translation happening now!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1836.39it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 918.80it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 762.46it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 600.82it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 590.83it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 361.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'assistant': 'Scientist',\n",
            " 'conversations': [{'from': 'user',\n",
            "                    'value': 'अनुसंधान और चुनौतीपूर्ण वातावरण में फसलों के '\n",
            "                             'सामने आने वाली प्रमुख चुनौतियों की पहचान करना।'},\n",
            "                   {'from': 'assistant',\n",
            "                    'value': 'केन्द्रीय कृषि एवं किसान कल्याण मंत्री, श्री '\n",
            "                             'राधा मोहन सिंह ने कहा है ई. ई. जेड में मत्स्यन '\n",
            "                             'के लिए पूर्व में लागू की गयी “लेटर ऑफ परिमट” या '\n",
            "                             '“एल. ओ. पी. ” व्यवस्था को जनवरी 2017 से बंद कर '\n",
            "                             'दिया गया है तथा पारम्परिक मछुआरों के हितों को '\n",
            "                             'ध्यान में रखते हुए 12 समुद्री मील के बाहर का '\n",
            "                             'क्षेत्र, जो भारत सरकार दवारा विनियमित होता है, '\n",
            "                             'उसमें विशेष प्रावधान किए गये हैं, जैसे कि मानसून '\n",
            "                             'के दौरान ई. ई. जेड. में लागू फिशिंग बैन से '\n",
            "                             'पारम्परिक मछुआरों को छूट दे दी गयी है. मत्स्यन '\n",
            "                             'के लिए एल. ई. डी. लाइट/अन्य कृत्रिम लाइट के '\n",
            "                             'प्रयोग पर तथा बुल-ट्रालिंग या पेयर-ट्रालिंग पर '\n",
            "                             'हाल में ही 10 नवंम्बर, 2017 को पूरी तरह से रोग '\n",
            "                             'लगा दी गयी है यह मृदा माइक्रोबियल प्रौद्योगिकी '\n",
            "                             'विकसित करने के लिए एक ठोस आधार प्रदान करेगा जो '\n",
            "                             'इन चुनौतियों का समाधान करेगा।'},\n",
            "                   {'from': 'user',\n",
            "                    'value': 'मौजूदा मृदा माइक्रोबियल प्रौद्योगिकियों और '\n",
            "                             'चुनौतीपूर्ण वातावरण में फसल उत्पादकता और लचीलेपन '\n",
            "                             'में सुधार लाने में उनकी प्रभावशीलता का मूल्यांकन '\n",
            "                             'करना।'},\n",
            "                   {'from': 'assistant',\n",
            "                    'value': 'मौजूदा मृदा माइक्रोबियल प्रौद्योगिकियों और '\n",
            "                             'चुनौतीपूर्ण वातावरण में फसल उत्पादकता और लचीलेपन '\n",
            "                             'में सुधार लाने में उनकी प्रभावशीलता का मूल्यांकन '\n",
            "                             'करने के लिए, मैं निम्नलिखित चरणों का पालन '\n",
            "                             'करूंगाः 1. साहित्य समीक्षाः मैं विकसित और '\n",
            "                             'परीक्षण की गई विभिन्न मृदा माइक्रोबियल '\n",
            "                             'प्रौद्योगिकियों की पहचान करने और जानकारी एकत्र '\n",
            "                             'करने के लिए एक व्यापक साहित्य समीक्षा करूंगा। '\n",
            "                             'इसमें वैज्ञानिक पत्रों, अनुसंधान लेखों और '\n",
            "                             'प्रतिष्ठित स्रोतों से प्राप्त रिपोर्टों का '\n",
            "                             'अध्ययन करना शामिल होगा। 2. डेटा संग्रहः मैं '\n",
            "                             'चुनौतीपूर्ण वातावरण में इन मिट्टी माइक्रोबियल '\n",
            "                             'प्रौद्योगिकियों के प्रदर्शन पर डेटा एकत्र '\n",
            "                             'करूंगा। इसमें फसल उपज, पोषक तत्व ग्रहण, रोग '\n",
            "                             'प्रतिरोध और समग्र पौधों के स्वास्थ्य के बारे में '\n",
            "                             'जानकारी शामिल हो सकती है। मैं उन विशिष्ट '\n",
            "                             'पर्यावरणीय स्थितियों पर भी विचार करूंगा, जिनके '\n",
            "                             'तहत इन प्रौद्योगिकियों का परीक्षण किया गया था। '\n",
            "                             'इस विश्लेषण में चुनौतीपूर्ण वातावरण में फसल '\n",
            "                             'उत्पादकता और लचीलेपन पर इन प्रौद्योगिकियों के '\n",
            "                             'प्रभाव का आकलन करना शामिल होगा. मैं उपयोग किए गए '\n",
            "                             'सूक्ष्मजीवों के प्रकार, अनुप्रयोग के तरीके, '\n",
            "                             'खुराक और विभिन्न फसलों के साथ संगतता जैसे कारकों '\n",
            "                             'पर विचार करूंगा. विशेषज्ञ परामर्शः मैं विभिन्न '\n",
            "                             'मिट्टी माइक्रोबियल प्रौद्योगिकियों की ताकत और '\n",
            "                             'सीमाओं में अंतर्दृष्टि प्राप्त करने के लिए मृदा '\n",
            "                             'सूक्ष्म जीव विज्ञान और कृषि विज्ञान के क्षेत्र '\n",
            "                             'के विशेषज्ञों के साथ परामर्श करूंगा. उनकी '\n",
            "                             'विशेषज्ञता वास्तविक दुनिया के कृषि परिदृश्यों '\n",
            "                             'में इन प्रौद्योगिकियों को लागू करने से जुड़े '\n",
            "                             'व्यावहारिक प्रभावों और संभावित चुनौतियों को '\n",
            "                             'समझने में मदद करेगी. मूल्यांकन मानदंड: मैं मृदा '\n",
            "                             'माइक्रोबियल प्रौद्योगिकियों की प्रभावशीलता का '\n",
            "                             'आकलन करने के लिए मूल्यांकन मानदंड स्थापित '\n",
            "                             'करूंगा. इन मानदंडों में फसल उत्पादन में सुधार, '\n",
            "                             'पोषक तत्व की उपलब्धता, रोग दमन, जल का उपयोग, '\n",
            "                             'दक्षता और मृदा स्वास्थ्य वृद्धि जैसे कारक शामिल '\n",
            "                             'हो सकते हैं। रिपोर्ट और सिफारिशः विश्लेषण और '\n",
            "                             'मूल्यांकन के आधार पर, मैं निष्कर्षों और '\n",
            "                             'सिफारिशों को संक्षेप में प्रस्तुत करने के लिए एक '\n",
            "                             'व्यापक रिपोर्ट तैयार करूंगा। यह रिपोर्ट फसल '\n",
            "                             'उत्पादकता में सुधार और चुनौतीपूर्ण वातावरण में '\n",
            "                             'लचीलापन के लिए सबसे प्रभावी मृदा माइक्रोबियल '\n",
            "                             'प्रौद्योगिकियों पर प्रकाश डालेगी।'}],\n",
            " 'length': 4,\n",
            " 'specified_task': 'मृदा माइक्रोबियल प्रौद्योगिकी विकसित करना जो चुनौतीपूर्ण '\n",
            "                   'वातावरण में फसल उत्पादकता और लचीलेपन में सुधार करे।',\n",
            " 'task': 'टिकाऊ कृषि पद्धतियों और पर्यावरण एवं फसल पैदावार के लिए उनके लाभों '\n",
            "         'पर चर्चा करना।',\n",
            " 'user': 'Farmer'}\n"
          ]
        }
      ],
      "source": [
        "sample = conversation_generator(user = 'Farmer',\n",
        "                                assistant = 'Scientist',\n",
        "                                # task = \"How to maximize the profit of a potato farmer\",\n",
        "                                lang = 'hi'\n",
        "                                )\n",
        "\n",
        "pprint.pprint(sample)\n",
        "# pprint.pprint(sample['conversations'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explicitly providing the task to the function"
      ],
      "metadata": {
        "id": "c_YkQzCWFtpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample = conversation_generator(user = 'Chef',\n",
        "                                assistant = 'Architecture',\n",
        "                                task = \"The architecture helps the chef is desgining his own restaurant \",\n",
        "                                lang = 'en'\n",
        "                                )\n",
        "\n",
        "pprint.pprint(sample)\n",
        "# pprint.pprint(sample['conversations'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZa0sg5FFa-v",
        "outputId": "9820d21a-e4ce-452c-d49f-b1a06f7a8a0d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original task prompt:\n",
            "The architecture helps the chef is desgining his own restaurant \n",
            "\n",
            "Specified task prompt:\n",
            "Design and construct a state-of-the-art, eco-friendly restaurant that seamlessly combines architectural innovation and sustainable practices. Incorporate unique elements such as a living wall of herbs, a rooftop garden, and innovative renewable energy systems to enhance the dining experience and inspire a new era of sustainable culinary delights.\n",
            "\n",
            "******************************************************************************************************************************************************\n",
            "Number of conversations =  4\n",
            "{'assistant': 'Architecture',\n",
            " 'conversations': [{'from': 'user',\n",
            "                    'value': 'Research and select sustainable building '\n",
            "                             'materials for the construction of the '\n",
            "                             'restaurant.'},\n",
            "                   {'from': 'assistant',\n",
            "                    'value': 'To research and select sustainable building '\n",
            "                             'materials for the construction of the '\n",
            "                             'restaurant, I will follow a systematic '\n",
            "                             'approach:\\n'\n",
            "                             '\\n'\n",
            "                             '1. Conduct research on sustainable building '\n",
            "                             'materials: I will explore various sources such '\n",
            "                             'as industry publications, green building '\n",
            "                             'certifications, and sustainable architecture '\n",
            "                             'websites to gather information on materials that '\n",
            "                             'are environmentally friendly, energy-efficient, '\n",
            "                             'and have a low carbon footprint.\\n'\n",
            "                             '\\n'\n",
            "                             '2. Consider renewable and recycled materials: I '\n",
            "                             'will prioritize materials that are renewable, '\n",
            "                             'such as bamboo, cork, or reclaimed wood. '\n",
            "                             'Additionally, I will look for materials made '\n",
            "                             'from recycled content, such as recycled steel or '\n",
            "                             'recycled glass.\\n'\n",
            "                             '\\n'\n",
            "                             '3. Evaluate the life cycle of materials: I will '\n",
            "                             'assess the environmental impact of each material '\n",
            "                             'by considering its entire life cycle, including '\n",
            "                             'extraction, production, transportation, '\n",
            "                             'installation, maintenance, and disposal. '\n",
            "                             'Materials with a lower environmental impact '\n",
            "                             'throughout their life cycle will be given '\n",
            "                             'preference.\\n'\n",
            "                             '\\n'\n",
            "                             '4. Assess durability and maintenance '\n",
            "                             'requirements: I will consider the durability and '\n",
            "                             'maintenance requirements of the materials to '\n",
            "                             'ensure they can withstand the demands of a '\n",
            "                             'restaurant environment and minimize the need for '\n",
            "                             'frequent replacements or repairs.\\n'\n",
            "                             '\\n'\n",
            "                             '5. Consider local availability: I will '\n",
            "                             'prioritize materials that are locally available '\n",
            "                             'to reduce transportation emissions and support '\n",
            "                             'the local economy.\\n'\n",
            "                             '\\n'\n",
            "                             '6. Consult with experts: If needed, I will '\n",
            "                             'consult with architects, engineers, or '\n",
            "                             'sustainability consultants who specialize in '\n",
            "                             'eco-friendly construction to gain further '\n",
            "                             'insights and recommendations.\\n'\n",
            "                             '\\n'\n",
            "                             'Based on the research and evaluation, I will '\n",
            "                             'compile a list of sustainable building materials '\n",
            "                             'that meet the criteria mentioned above. This '\n",
            "                             'list will include options for flooring, walls, '\n",
            "                             'insulation, roofing, and other relevant '\n",
            "                             \"components of the restaurant's construction.\"},\n",
            "                   {'from': 'user',\n",
            "                    'value': 'Design an open and inviting floor plan for the '\n",
            "                             'restaurant that maximizes natural light and '\n",
            "                             'promotes a seamless flow between indoor and '\n",
            "                             'outdoor spaces.'},\n",
            "                   {'from': 'assistant',\n",
            "                    'value': 'To design an open and inviting floor plan for '\n",
            "                             'the restaurant that maximizes natural light and '\n",
            "                             'promotes a seamless flow between indoor and '\n",
            "                             'outdoor spaces, I will consider the following '\n",
            "                             'elements:\\n'\n",
            "                             '\\n'\n",
            "                             '1. Orientation and layout: I will analyze the '\n",
            "                             \"site's orientation and position the main dining \"\n",
            "                             'area and windows to maximize the intake of '\n",
            "                             'natural light. Placing the dining area on the '\n",
            "                             'southern side of the building can help capture '\n",
            "                             'more sunlight throughout the day. I will also '\n",
            "                             'ensure that the layout allows for easy access to '\n",
            "                             'outdoor spaces, such as a patio or rooftop '\n",
            "                             'garden.\\n'\n",
            "                             '\\n'\n",
            "                             '2. Use of glass and windows: I will incorporate '\n",
            "                             'large windows and glass walls to allow ample '\n",
            "                             'natural light to penetrate the interior space. '\n",
            "                             'This will create a sense of openness and '\n",
            "                             'connection with the surrounding environment. '\n",
            "                             'Additionally, I will consider using '\n",
            "                             'low-emissivity (low-e) glass to minimize heat '\n",
            "                             'gain and loss, improving energy efficiency.\\n'\n",
            "                             '\\n'\n",
            "                             '3. Skylights and light wells: To further enhance '\n",
            "                             'natural light, I will strategically position '\n",
            "                             'skylights or light wells in areas that require '\n",
            "                             'additional illumination, such as corridors or '\n",
            "                             'private dining spaces. This will reduce the need '\n",
            "                             'for artificial lighting during the day.\\n'\n",
            "                             '\\n'\n",
            "                             '4. Flexible seating arrangements: I will design '\n",
            "                             'the floor plan to accommodate various seating '\n",
            "                             'arrangements, including movable furniture and '\n",
            "                             'partitions. This flexibility will allow for easy '\n",
            "                             'reconfiguration of the space to adapt to '\n",
            "                             'different dining experiences and events.\\n'\n",
            "                             '\\n'\n",
            "                             '5. Integration of outdoor spaces: I will create '\n",
            "                             'a seamless transition between indoor and outdoor '\n",
            "                             'spaces by incorporating features like large '\n",
            "                             'sliding or folding glass doors that open up to a '\n",
            "                             'patio or courtyard. This will provide an '\n",
            "                             'opportunity for customers to dine al fresco and '\n",
            "                             'enjoy the surrounding environment.\\n'\n",
            "                             '\\n'\n",
            "                             '6. Natural ventilation: I will consider '\n",
            "                             'incorporating natural ventilation strategies, '\n",
            "                             'such as operable windows and ceiling fans, to '\n",
            "                             'promote airflow and reduce reliance on '\n",
            "                             'mechanical cooling systems. This will enhance '\n",
            "                             'the comfort of the dining experience while '\n",
            "                             'minimizing energy consumption.\\n'\n",
            "                             '\\n'\n",
            "                             'By considering these design elements, I will '\n",
            "                             'create an open and inviting floor plan that '\n",
            "                             'maximizes natural light, promotes a seamless '\n",
            "                             'flow between indoor and outdoor spaces, and '\n",
            "                             'enhances the overall dining experience.'}],\n",
            " 'length': 4,\n",
            " 'specified_task': 'Design and construct a state-of-the-art, eco-friendly '\n",
            "                   'restaurant that seamlessly combines architectural '\n",
            "                   'innovation and sustainable practices. Incorporate unique '\n",
            "                   'elements such as a living wall of herbs, a rooftop garden, '\n",
            "                   'and innovative renewable energy systems to enhance the '\n",
            "                   'dining experience and inspire a new era of sustainable '\n",
            "                   'culinary delights.',\n",
            " 'task': 'The architecture helps the chef is desgining his own restaurant ',\n",
            " 'user': 'Chef'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a-Ga19VmFpP1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}